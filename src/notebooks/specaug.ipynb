{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as _T\n",
    "from torch.utils.data import DataLoader\n",
    "import librosa\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from dataloaders.rawaudiodataset import RawAudioDataset\n",
    "from dataloaders.audiodataset  import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  im = axs.imshow(spec, origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def get_spectrogram(waveform,\n",
    "    n_fft = 400,\n",
    "    win_len = None,\n",
    "    hop_len = None,\n",
    "    power = 2.0,\n",
    "):\n",
    "  spectrogram = T.Spectrogram(\n",
    "      n_fft=n_fft,\n",
    "      win_length=win_len,\n",
    "      hop_length=hop_len,\n",
    "      center=True,\n",
    "      pad_mode=\"reflect\",\n",
    "      power=power,\n",
    "  )\n",
    "  return spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _custom_collate(batch_):\n",
    "    def contains_none(b):\n",
    "        for elem in b:\n",
    "            if elem is None:\n",
    "                return False\n",
    "        return True\n",
    "    batch = list(filter(lambda x: contains_none(x), batch_))\n",
    "    input = torch.stack([b[0] for b in batch])\n",
    "    label = torch.stack([b[1] for b in batch])\n",
    "    if len(batch[0]) == 2:\n",
    "        return input, label\n",
    "    filepath = [b[2] for b in batch]\n",
    "    return input, label, filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_file = \"/Users/test/Documents/Projects/Master/birds-generation/data/cleaned_train/Alaarv_song/nips4b_birds_trainfile604-a691a8.npy\"\n",
    "audio_spec = np.load(sample_file)\n",
    "audio_spec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file =  os.path.splitext(sample_file)[0]+\".wav\"\n",
    "assert os.path.isfile(audio_file), (audio_file, sample_file)\n",
    "audio, sr = torchaudio.load(audio_file)\n",
    "spec = get_spectrogram(audio)\n",
    "plot_spectrogram(spec[0], title=\"Original\")\n",
    "\n",
    "# masking = T.FrequencyMasking(freq_mask_param=80)\n",
    "# spec = masking(spec)\n",
    "\n",
    "plot_spectrogram(spec[0], title=\"Masked along frequency axis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate an object of the class rawaudiodataset\n",
    "classes = os.listdir(\"../../data/cleaned_train\") \n",
    "#remove .DS_Store from the list of classes\n",
    "classes = [x for x in classes if x != \".DS_Store\"]\n",
    "print(\"Classes in the dataset: \", classes)\n",
    "\n",
    "# transform = T.FrequencyMasking(freq_mask_param=80)\n",
    "transform = _T.Compose(\n",
    "    [\n",
    "        T.FrequencyMasking(freq_mask_param=10),\n",
    "        T.TimeMasking(time_mask_param=10),\n",
    "        _T.Resize(size=(512, 32))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# transform = []\n",
    "#Create a dataset object\n",
    "dataset = RawAudioDataset(data_path=\"../../data/cleaned_train.txt\", root_dir=\"../../data/\", classes_name=classes, sr=16000, window_length=16384, use_spectrogram=True, transform=transform)\n",
    "# dataset = AudioDataset(data_path=\"../../data/cleaned_train.txt\", root_dir=\"../../data/\", classes_name=classes, sr=16000, window_length=16384, use_spectrogram=True, transforms=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True, num_workers=0, collate_fn=_custom_collate)\n",
    "for i, sample in enumerate(dataloader):\n",
    "  print(sample[0].shape, sample[1])\n",
    "  # plot_spectrogram(sample[0], title=\"Original\")\n",
    "  # if i > 10:\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('scologan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7 (default, May  6 2020, 04:59:01) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e93dd7469fb6698e09fbfba73e5ce40dc1dc5e356aab3eb579a371dc5e93993c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
